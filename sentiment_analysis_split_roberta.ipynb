{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc6231b",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0554f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[K     |█████████████████               | 309.1 MB 191.7 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.22.4)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.46.3)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 103.6 MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 128.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 156.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 40.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 132.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 101.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 126.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 124.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 118.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 120.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Installing collected packages: wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-pasta-0.2.0 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88fe908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 18:03:41.818801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 18:03:41.964410: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-23 18:03:42.639145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-23 18:03:42.639245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-23 18:03:42.639251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0', '/device:GPU:1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 18:03:43.570969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 18:03:44.612145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 33741 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2022-10-23 18:03:44.613667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:1 with 37221 MB memory:  -> device: 1, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e43bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9433c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 36.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5f00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "import time\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabfd672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/asurion_f22_jw/Asurion-customer-propensity\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6418584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sales_offer_date</th>\n",
       "      <th>accepted_flg</th>\n",
       "      <th>encrypted_collated_transcription</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f81e2619aae688a3a814da7f58afdecb9720e9fdd5070...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech for speaki...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bcb2c2dd3e29b8b7ba6c0cf8c7232c8637d6bc73a760...</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>False</td>\n",
       "      <td>[CLIENT] tech My name is [NAME]. May I have yo...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1eeaa4c1fe8030bb6f0deaa81a13b468001c699586f46...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for call. tech you're speaking w...</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5bf5d93c818534d9edcff8cbb45f28d3e0438cf7ab7850...</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c484a81de8c25bcfb9d95f36976cfb425a3d2c7602a93c...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Barcode Coa...</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID sales_offer_date  \\\n",
       "0  4f81e2619aae688a3a814da7f58afdecb9720e9fdd5070...       2022-05-31   \n",
       "1  03bcb2c2dd3e29b8b7ba6c0cf8c7232c8637d6bc73a760...       2022-05-13   \n",
       "2  c1eeaa4c1fe8030bb6f0deaa81a13b468001c699586f46...       2022-05-29   \n",
       "3  5bf5d93c818534d9edcff8cbb45f28d3e0438cf7ab7850...       2022-05-22   \n",
       "4  c484a81de8c25bcfb9d95f36976cfb425a3d2c7602a93c...       2022-05-21   \n",
       "\n",
       "   accepted_flg                   encrypted_collated_transcription  \\\n",
       "0         False  Thank you for calling [CLIENT] Tech for speaki...   \n",
       "1         False  [CLIENT] tech My name is [NAME]. May I have yo...   \n",
       "2         False  Hi. Thank you for call. tech you're speaking w...   \n",
       "3         False  Thank you for calling [CLIENT] Tech Coach. My ...   \n",
       "4         False  Hi. Thank you for calling [CLIENT] Barcode Coa...   \n",
       "\n",
       "   number_of_words  \n",
       "0              113  \n",
       "1              454  \n",
       "2             1674  \n",
       "3             1129  \n",
       "4              668  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/transcript_may_encoded_100.csv')\n",
    "# df = pd.read_csv('data/transcript_march_collated_encoded.csv')\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "# df = df[df['accepted_flg'] == True]\n",
    "df['number_of_words'] = df.encrypted_collated_transcription.apply(lambda x: len(x.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e09e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97227ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_token_nltk(str):\n",
    "    sent_tokenize_list = sent_tokenize(str)\n",
    "    return sent_tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66a2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ae2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stanza\n",
    "# def sentence_token_stanza(str):\n",
    "#     nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "#     doc = nlp(str)\n",
    "#     sent_tokenize_list = [sentence.text for sentence in doc.sentences]\n",
    "#     return sent_tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faddf87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████| 747/747 [00:00<00:00, 832kB/s]\n",
      "Downloading: 100%|███████████████████████████| 499M/499M [00:05<00:00, 97.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Import generic wrappers\n",
    "# from transformers import AutoModel, AutoTokenizer \n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define the model repo\n",
    "myckpt = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "mytokenizer = AutoTokenizer\n",
    "device = torch.device(str(\"cuda\") if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Download pytorch model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(myckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf72d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_inputs(text, checkpoint = myckpt, t=mytokenizer):\n",
    "    tokenizer = t.from_pretrained(myckpt, is_split_into_words = True, model_max_length=512)\n",
    "    return tokenizer(text, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bff4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df, text_col:str, length:int):\n",
    "    '''\n",
    "    Function to do sentiment analysis by paragraphs into shorter pieces\n",
    "    '''\n",
    "    start=time.time()\n",
    "    for i in df.index:\n",
    "        iter_start=time.time()\n",
    "        # break paragraphs into sentences\n",
    "        sent_list = sentence_token_nltk(df.loc[i, text_col])\n",
    "        count = 0\n",
    "        token_list, input_list = [], []\n",
    "        mask_list, attention_list = [], []\n",
    "        for sent in sent_list:\n",
    "            # tokenize sentences\n",
    "            res = tokenize_inputs(sent)\n",
    "            tokens, masks = res['input_ids'], res['attention_mask']\n",
    "            count += len(tokens)\n",
    "\n",
    "            if count <= length:\n",
    "                token_list = token_list + tokens\n",
    "                mask_list = mask_list + masks\n",
    "            else:    \n",
    "                input_list.append(token_list)\n",
    "                attention_list.append(mask_list)\n",
    "                token_list = tokens\n",
    "                mask_list = masks\n",
    "                count=len(tokens)\n",
    "\n",
    "        input_list.append(token_list)\n",
    "        attention_list.append(mask_list) \n",
    "        for j in range(len(input_list)):      \n",
    "            # get required padding length\n",
    "            pad_len = length - len(input_list[j])\n",
    "\n",
    "            # check if list length satisfies required chunk size\n",
    "            if pad_len > 0:\n",
    "                # if padding length is more than 0, we gonna add padding\n",
    "                input_list[j] = input_list[j] + [0] * pad_len\n",
    "                attention_list[j] = attention_list[j] + [0] * pad_len\n",
    "\n",
    "        input_ids = torch.FloatTensor(input_list).to(device)\n",
    "        attention_mask = torch.FloatTensor(attention_list).to(device)\n",
    "        input_dict = {'input_ids': input_ids.long(),'attention_mask': attention_mask.int()}\n",
    "        outputs = model(**input_dict)\n",
    "#         print(outputs)\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "#         print(probs)\n",
    "        probs = probs.mean(dim=0)\n",
    "#         print(probs)\n",
    "        winner = torch.argmax(probs).item()\n",
    "#         print(winner)\n",
    "#         Labels: 0 -> Negative; 1 -> Neutral; 2 -> Positive\n",
    "        df.loc[i, 'sentiment'] = ['Negative', 'Neutral', 'Positive'][winner]\n",
    "        df.loc[i, 'runtime'] = round(time.time()-iter_start, 2)\n",
    "    print(round(time.time()-start, 2), 'seconds')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb918095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████| 899k/899k [00:00<00:00, 5.30MB/s]\n",
      "Downloading: 100%|███████████████████████████| 456k/456k [00:00<00:00, 3.17MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 150/150 [00:00<00:00, 259kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6441.94 seconds\n"
     ]
    }
   ],
   "source": [
    "df1=sentiment_analysis(df = df, text_col='encrypted_collated_transcription', length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a96014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('sa_w_twitter.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb34397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sales_offer_date</th>\n",
       "      <th>accepted_flg</th>\n",
       "      <th>encrypted_collated_transcription</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f81e2619aae688a3a814da7f58afdecb9720e9fdd5070...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech for speaki...</td>\n",
       "      <td>113</td>\n",
       "      <td>Negative</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bcb2c2dd3e29b8b7ba6c0cf8c7232c8637d6bc73a760...</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>False</td>\n",
       "      <td>[CLIENT] tech My name is [NAME]. May I have yo...</td>\n",
       "      <td>454</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>48.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1eeaa4c1fe8030bb6f0deaa81a13b468001c699586f46...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for call. tech you're speaking w...</td>\n",
       "      <td>1674</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>171.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5bf5d93c818534d9edcff8cbb45f28d3e0438cf7ab7850...</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>1129</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>73.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c484a81de8c25bcfb9d95f36976cfb425a3d2c7602a93c...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Barcode Coa...</td>\n",
       "      <td>668</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b6716b08ca0380e7b5c7e9b78fcecf5787ccf3d61d1869...</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling Coach. This is Sean spea...</td>\n",
       "      <td>2967</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>343.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9f900ab27f1f249ce94d45947421b50ce9b9a85ec0d909...</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>True</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. Ben...</td>\n",
       "      <td>7032</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>723.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143fada0c669611e23e414d405a4f528a2528718a20c00...</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>False</td>\n",
       "      <td>Morning. Thanks for [CLIENT] Tech Coach. My na...</td>\n",
       "      <td>2561</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>217.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8cbccda49661f95352e153157f8894c4d2d8e52d28740b...</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>False</td>\n",
       "      <td>thank Hello? Hi. Thank you for calling [CLIENT...</td>\n",
       "      <td>1661</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>210.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46f3a9e86aa971a85d0d4cda2a886233d88f9e1da57eff...</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for [CLIENT] Tech Coach. My name...</td>\n",
       "      <td>536</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>73.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb8d77d937410b5110748f5ef1a5eaf39e8fe6d5e5c258...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>False</td>\n",
       "      <td>Thanks you for calling tech Coach. My name is ...</td>\n",
       "      <td>2087</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>157.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c0a9ab591ee552643a17e61b7167805b3047475e9a6897...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Yeah. Yeah. This means that work. Thank you fo...</td>\n",
       "      <td>3418</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>333.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b623fb1f52c247a19423c7c9a8460ddf95033b8458ab8b...</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach name...</td>\n",
       "      <td>1439</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>115.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b5b23536a07e5e7b420c0b93dd25d1b8a30b428e7c2c6e...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank Thank you for calling [CLIENT] Tech Coac...</td>\n",
       "      <td>700</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>78.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>263801a45c0fe066e945b5ef067cbc837f89d5aa12dcde...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank Thank you for I'm talking [CLIENT] Tech ...</td>\n",
       "      <td>1228</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>100.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d7b69493a1d43af6616a0fb7441afe4d40b65c1eeb8412...</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok. Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "      <td>822</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>100.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24d2c79d3a6b8a27bdab1371e3d8ecbbb6348128f47ddc...</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>606</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>80.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53414ecdf02604b143202f79d92377dda69307f730e492...</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>Hello is [CLIENT] Coach santiago Hello in it's...</td>\n",
       "      <td>762</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>109.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>797e283c3257ca5f7bb9e101c69cbefb0debb8f0207e2c...</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>True</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Tech Coach ...</td>\n",
       "      <td>995</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>103.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a4c131b826f1a6c233e989cef70447f2029bac90670ab5...</td>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for Contacting [CLIENT] Tech Coach M...</td>\n",
       "      <td>1390</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>131.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>d94aa5db28106d252eb8c1f76816c1607ff4999462bc45...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] [CLIENT] Tech C...</td>\n",
       "      <td>1197</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>144.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>56a2e1ae957d29268c98c0ecb01a0e2f17e385aeefb224...</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank for calling [CLIENT] My name is [NAM...</td>\n",
       "      <td>2443</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>237.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a38a07ce34e179da48869142cd39e4bbfd9c62a5344071...</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok. Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "      <td>590</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>59.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5da3745d3fd31ba16307659045da55b0d2adecc6dc19a1...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>True</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "      <td>243</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>23.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8291f34b98fb7eb8d3496549cd1d9a9b8ab76be0aa5d1e...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok Bye. Ok. Hi there. Thank you for calling [C...</td>\n",
       "      <td>971</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>108.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b3ae08bd35ac9105afe264757638cef0aa7a09e89fd367...</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank Right? Echo coach. My name art. i have y...</td>\n",
       "      <td>1564</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>155.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4437ba6862f2c393c6a526ca6db431980863207b307f78...</td>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>True</td>\n",
       "      <td>ok Thank you for calling [CLIENT] Tech Coach. ...</td>\n",
       "      <td>1160</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>113.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1eb9199f3bf267849224d04299853bbdd3e98e17cf2047...</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>False</td>\n",
       "      <td>Hello? Thank you for calling [CLIENT]. I'll be...</td>\n",
       "      <td>632</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>71.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5bf4a5790d48de0ba24b51f9faafc1f3d8c416cfc3bbdd...</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "      <td>987</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>102.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>e02e455154679a491c9158ac9410a5750111fbcd9bb413...</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>2557</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>298.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b5e3c6834416b9331d30804c0897655b2cb46edfac58fa...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Tech Coach ...</td>\n",
       "      <td>3317</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>305.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2a4b519cda229c20d0d42573d60529be8f245259410f7a...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>2625</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>277.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>043e01bd3f72b575283f9d09343e6168a031fd0436e527...</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you so much for calling [CLIENT]. My...</td>\n",
       "      <td>837</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>82.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9c027f04ee4ead74d89a4f4c11c9ab4fc8291c7516b5f2...</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>False</td>\n",
       "      <td>you. Thank you for calling [CLIENT] Tech Coach...</td>\n",
       "      <td>1570</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>152.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>88a10ea5c732fe5a13846b393abf72c1b236e60b946084...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you so much for waiting on the line....</td>\n",
       "      <td>731</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>81.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>56630285d2f79fd2621feafd26482f3889b21c596c6008...</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>False</td>\n",
       "      <td>ok. Hi, thank you for calling [CLIENT] Tech Co...</td>\n",
       "      <td>1397</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>171.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>deb868e96a0f734afdb58780178bd07e8c89cb8f68c53a...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok. This for [CLIENT] Tech Coach. go. number A...</td>\n",
       "      <td>173</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>37.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>559a8b3b0eb88c5e3e00054f8d5422873ef48f8bd34c70...</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. This is Playing from [CLIENT]. Can I get y...</td>\n",
       "      <td>478</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>38.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>65f2764772377e4888834944694a719d133aae86fb3df5...</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank. For calling. My name is [NAME]'ll be? d...</td>\n",
       "      <td>591</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>52.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2ba8921d31f0f71aceae41cf5b1d9eda10eb9fe819637a...</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "      <td>1062</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>103.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8d855f94232fe31d7add27eb1b47eb6812bf476f67f5ee...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>Tech Coach. My name may I have your first last...</td>\n",
       "      <td>731</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>78.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2dbb76c19a88383660f399d3530e0ecfd5afc15d76c669...</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>False</td>\n",
       "      <td>calling. Too. My name is [NAME]. May I have yo...</td>\n",
       "      <td>396</td>\n",
       "      <td>Negative</td>\n",
       "      <td>39.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>d532eea7e3f4dc190de023acaeef9da75e21e0ae037ea3...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi. This for [CLIENT] Tech Coach. My name is [...</td>\n",
       "      <td>958</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>105.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>b1391483ef638c2f4d187bee9f0e7c193dbd69a141603c...</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok. Hi. Thank you for calling [CLIENT] Tech Co...</td>\n",
       "      <td>790</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>79.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3042a7766bba46e074ed6653eefd4596809a6552c73265...</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok. Thank you for calling Asurion. This is May...</td>\n",
       "      <td>2090</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>189.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1c8fc4ac147dcca314c3ad0b9f2cd9ef0741250dbe2376...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes, It didn't really a book a different That....</td>\n",
       "      <td>520</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>68.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ID sales_offer_date  \\\n",
       "0   4f81e2619aae688a3a814da7f58afdecb9720e9fdd5070...       2022-05-31   \n",
       "1   03bcb2c2dd3e29b8b7ba6c0cf8c7232c8637d6bc73a760...       2022-05-13   \n",
       "2   c1eeaa4c1fe8030bb6f0deaa81a13b468001c699586f46...       2022-05-29   \n",
       "3   5bf5d93c818534d9edcff8cbb45f28d3e0438cf7ab7850...       2022-05-22   \n",
       "4   c484a81de8c25bcfb9d95f36976cfb425a3d2c7602a93c...       2022-05-21   \n",
       "5   b6716b08ca0380e7b5c7e9b78fcecf5787ccf3d61d1869...       2022-05-03   \n",
       "6   9f900ab27f1f249ce94d45947421b50ce9b9a85ec0d909...       2022-05-17   \n",
       "7   143fada0c669611e23e414d405a4f528a2528718a20c00...       2022-05-03   \n",
       "8   8cbccda49661f95352e153157f8894c4d2d8e52d28740b...       2022-05-09   \n",
       "9   46f3a9e86aa971a85d0d4cda2a886233d88f9e1da57eff...       2022-05-19   \n",
       "10  bb8d77d937410b5110748f5ef1a5eaf39e8fe6d5e5c258...       2022-05-24   \n",
       "11  c0a9ab591ee552643a17e61b7167805b3047475e9a6897...       2022-05-21   \n",
       "12  b623fb1f52c247a19423c7c9a8460ddf95033b8458ab8b...       2022-05-01   \n",
       "13  b5b23536a07e5e7b420c0b93dd25d1b8a30b428e7c2c6e...       2022-05-24   \n",
       "14  263801a45c0fe066e945b5ef067cbc837f89d5aa12dcde...       2022-05-31   \n",
       "15  d7b69493a1d43af6616a0fb7441afe4d40b65c1eeb8412...       2022-05-23   \n",
       "16  24d2c79d3a6b8a27bdab1371e3d8ecbbb6348128f47ddc...       2022-05-12   \n",
       "17  53414ecdf02604b143202f79d92377dda69307f730e492...       2022-05-08   \n",
       "18  797e283c3257ca5f7bb9e101c69cbefb0debb8f0207e2c...       2022-05-06   \n",
       "19  a4c131b826f1a6c233e989cef70447f2029bac90670ab5...       2022-05-30   \n",
       "20  d94aa5db28106d252eb8c1f76816c1607ff4999462bc45...       2022-05-21   \n",
       "21  56a2e1ae957d29268c98c0ecb01a0e2f17e385aeefb224...       2022-05-22   \n",
       "22  a38a07ce34e179da48869142cd39e4bbfd9c62a5344071...       2022-05-12   \n",
       "23  5da3745d3fd31ba16307659045da55b0d2adecc6dc19a1...       2022-05-31   \n",
       "24  8291f34b98fb7eb8d3496549cd1d9a9b8ab76be0aa5d1e...       2022-05-28   \n",
       "25  b3ae08bd35ac9105afe264757638cef0aa7a09e89fd367...       2022-05-25   \n",
       "26  4437ba6862f2c393c6a526ca6db431980863207b307f78...       2022-05-30   \n",
       "27  1eb9199f3bf267849224d04299853bbdd3e98e17cf2047...       2022-05-03   \n",
       "28  5bf4a5790d48de0ba24b51f9faafc1f3d8c416cfc3bbdd...       2022-05-12   \n",
       "29  e02e455154679a491c9158ac9410a5750111fbcd9bb413...       2022-05-27   \n",
       "30  b5e3c6834416b9331d30804c0897655b2cb46edfac58fa...       2022-05-21   \n",
       "31  2a4b519cda229c20d0d42573d60529be8f245259410f7a...       2022-05-28   \n",
       "32  043e01bd3f72b575283f9d09343e6168a031fd0436e527...       2022-05-11   \n",
       "33  9c027f04ee4ead74d89a4f4c11c9ab4fc8291c7516b5f2...       2022-05-27   \n",
       "34  88a10ea5c732fe5a13846b393abf72c1b236e60b946084...       2022-05-21   \n",
       "35  56630285d2f79fd2621feafd26482f3889b21c596c6008...       2022-05-27   \n",
       "36  deb868e96a0f734afdb58780178bd07e8c89cb8f68c53a...       2022-05-31   \n",
       "37  559a8b3b0eb88c5e3e00054f8d5422873ef48f8bd34c70...       2022-05-16   \n",
       "38  65f2764772377e4888834944694a719d133aae86fb3df5...       2022-05-18   \n",
       "39  2ba8921d31f0f71aceae41cf5b1d9eda10eb9fe819637a...       2022-05-10   \n",
       "40  8d855f94232fe31d7add27eb1b47eb6812bf476f67f5ee...       2022-05-31   \n",
       "41  2dbb76c19a88383660f399d3530e0ecfd5afc15d76c669...       2022-05-17   \n",
       "42  d532eea7e3f4dc190de023acaeef9da75e21e0ae037ea3...       2022-05-28   \n",
       "43  b1391483ef638c2f4d187bee9f0e7c193dbd69a141603c...       2022-05-14   \n",
       "44  3042a7766bba46e074ed6653eefd4596809a6552c73265...       2022-05-25   \n",
       "45  1c8fc4ac147dcca314c3ad0b9f2cd9ef0741250dbe2376...       2022-05-29   \n",
       "\n",
       "    accepted_flg                   encrypted_collated_transcription  \\\n",
       "0          False  Thank you for calling [CLIENT] Tech for speaki...   \n",
       "1          False  [CLIENT] tech My name is [NAME]. May I have yo...   \n",
       "2          False  Hi. Thank you for call. tech you're speaking w...   \n",
       "3          False  Thank you for calling [CLIENT] Tech Coach. My ...   \n",
       "4          False  Hi. Thank you for calling [CLIENT] Barcode Coa...   \n",
       "5          False  Thank you for calling Coach. This is Sean spea...   \n",
       "6           True  Thank you for calling [CLIENT] Tech Coach. Ben...   \n",
       "7          False  Morning. Thanks for [CLIENT] Tech Coach. My na...   \n",
       "8          False  thank Hello? Hi. Thank you for calling [CLIENT...   \n",
       "9          False  Hi. Thank you for [CLIENT] Tech Coach. My name...   \n",
       "10         False  Thanks you for calling tech Coach. My name is ...   \n",
       "11         False  Yeah. Yeah. This means that work. Thank you fo...   \n",
       "12         False  Thank you for calling [CLIENT] Tech Coach name...   \n",
       "13         False  Thank Thank you for calling [CLIENT] Tech Coac...   \n",
       "14         False  Thank Thank you for I'm talking [CLIENT] Tech ...   \n",
       "15         False  Ok. Thank you for calling [CLIENT] Tech Coach....   \n",
       "16         False  Thank you for calling [CLIENT] Tech Coach. My ...   \n",
       "17         False  Hello is [CLIENT] Coach santiago Hello in it's...   \n",
       "18          True  Hi. Thank you for calling [CLIENT] Tech Coach ...   \n",
       "19         False  Thank you for Contacting [CLIENT] Tech Coach M...   \n",
       "20         False  Thank you for calling [CLIENT] [CLIENT] Tech C...   \n",
       "21         False  Hi. Thank for calling [CLIENT] My name is [NAM...   \n",
       "22         False  Ok. Thank you for calling [CLIENT] Tech Coach....   \n",
       "23          True  Hi. Thank you for calling [CLIENT] Tech Coach....   \n",
       "24         False  Ok Bye. Ok. Hi there. Thank you for calling [C...   \n",
       "25         False  Thank Right? Echo coach. My name art. i have y...   \n",
       "26          True  ok Thank you for calling [CLIENT] Tech Coach. ...   \n",
       "27         False  Hello? Thank you for calling [CLIENT]. I'll be...   \n",
       "28         False  Hi. Thank you for calling [CLIENT] Tech Coach....   \n",
       "29         False  Thank you for calling [CLIENT] Tech Coach. My ...   \n",
       "30         False  Hi. Thank you for calling [CLIENT] Tech Coach ...   \n",
       "31         False  thank you for calling [CLIENT] Tech Coach. My ...   \n",
       "32         False  Hi. Thank you so much for calling [CLIENT]. My...   \n",
       "33         False  you. Thank you for calling [CLIENT] Tech Coach...   \n",
       "34         False  Hi. Thank you so much for waiting on the line....   \n",
       "35         False  ok. Hi, thank you for calling [CLIENT] Tech Co...   \n",
       "36         False  Ok. This for [CLIENT] Tech Coach. go. number A...   \n",
       "37         False  Hi. This is Playing from [CLIENT]. Can I get y...   \n",
       "38         False  Thank. For calling. My name is [NAME]'ll be? d...   \n",
       "39         False  Hi. Thank you for calling [CLIENT] Tech Coach....   \n",
       "40         False  Tech Coach. My name may I have your first last...   \n",
       "41         False  calling. Too. My name is [NAME]. May I have yo...   \n",
       "42         False  Hi. This for [CLIENT] Tech Coach. My name is [...   \n",
       "43         False  Ok. Hi. Thank you for calling [CLIENT] Tech Co...   \n",
       "44         False  Ok. Thank you for calling Asurion. This is May...   \n",
       "45         False  Yes, It didn't really a book a different That....   \n",
       "\n",
       "    number_of_words sentiment  runtime  \n",
       "0               113  Negative    18.34  \n",
       "1               454   Neutral    48.41  \n",
       "2              1674   Neutral   171.12  \n",
       "3              1129   Neutral    73.17  \n",
       "4               668   Neutral    67.75  \n",
       "5              2967   Neutral   343.75  \n",
       "6              7032   Neutral   723.68  \n",
       "7              2561   Neutral   217.48  \n",
       "8              1661   Neutral   210.91  \n",
       "9               536   Neutral    73.96  \n",
       "10             2087   Neutral   157.87  \n",
       "11             3418   Neutral   333.25  \n",
       "12             1439   Neutral   115.47  \n",
       "13              700   Neutral    78.80  \n",
       "14             1228   Neutral   100.59  \n",
       "15              822   Neutral   100.56  \n",
       "16              606   Neutral    80.98  \n",
       "17              762   Neutral   109.55  \n",
       "18              995   Neutral   103.85  \n",
       "19             1390   Neutral   131.27  \n",
       "20             1197   Neutral   144.74  \n",
       "21             2443   Neutral   237.89  \n",
       "22              590   Neutral    59.26  \n",
       "23              243   Neutral    23.60  \n",
       "24              971   Neutral   108.84  \n",
       "25             1564   Neutral   155.66  \n",
       "26             1160   Neutral   113.44  \n",
       "27              632   Neutral    71.12  \n",
       "28              987   Neutral   102.13  \n",
       "29             2557   Neutral   298.17  \n",
       "30             3317   Neutral   305.24  \n",
       "31             2625   Neutral   277.32  \n",
       "32              837   Neutral    82.34  \n",
       "33             1570   Neutral   152.84  \n",
       "34              731   Neutral    81.84  \n",
       "35             1397   Neutral   171.88  \n",
       "36              173   Neutral    37.78  \n",
       "37              478   Neutral    38.62  \n",
       "38              591   Neutral    52.91  \n",
       "39             1062   Neutral   103.43  \n",
       "40              731   Neutral    78.96  \n",
       "41              396  Negative    39.70  \n",
       "42              958   Neutral   105.22  \n",
       "43              790   Neutral    79.72  \n",
       "44             2090   Neutral   189.69  \n",
       "45              520   Neutral    68.80  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a8c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[26, 'encrypted_collated_transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5354097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7032"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['number_of_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876bb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
