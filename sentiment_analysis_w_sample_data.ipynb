{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4310802e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4c11b",
   "metadata": {},
   "source": [
    "## Fine-tuned Sentiment Analysis Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8812694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 03:56:39.868427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-13 03:56:40.040300: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-13 03:56:40.573190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-13 03:56:40.573267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-13 03:56:40.573273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset, ClassLabel, load_from_disk, DatasetDict, load_metric\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import pipeline\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91ed1423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sales_offer_date</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e87397307d1da391a6a5cdce07d36615e212dd2112249e...</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>I am Is Protech Contacting Support to technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d7b2a81926ca34e042635eb664007b4bd64c7853b529f...</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi there. Thank you for calling [CLIENT] Tech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9366cba76b738bf36e28d11398bc4d40e34be1ec2ca88...</td>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT]. My name is [NA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac3f93e0220b4b416d63f3b5859386ca77f7862a8afbb7...</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18adf38a3b21b9c0736af624a18749b95b8896282876a2...</td>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>False</td>\n",
       "      <td>Hi, Thank you for calling [CLIENT] Tech Coach....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID sales_offer_date  label  \\\n",
       "0  e87397307d1da391a6a5cdce07d36615e212dd2112249e...       2022-05-31  False   \n",
       "1  1d7b2a81926ca34e042635eb664007b4bd64c7853b529f...       2022-05-20  False   \n",
       "2  f9366cba76b738bf36e28d11398bc4d40e34be1ec2ca88...       2022-05-02  False   \n",
       "3  ac3f93e0220b4b416d63f3b5859386ca77f7862a8afbb7...       2022-05-06  False   \n",
       "4  18adf38a3b21b9c0736af624a18749b95b8896282876a2...       2022-05-02  False   \n",
       "\n",
       "                                                text  \n",
       "0  I am Is Protech Contacting Support to technica...  \n",
       "1  Hi there. Thank you for calling [CLIENT] Tech ...  \n",
       "2  Thank you for calling [CLIENT]. My name is [NA...  \n",
       "3  Thank you for calling [CLIENT] Tech Coach. My ...  \n",
       "4  Hi, Thank you for calling [CLIENT] Tech Coach....  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the full data\n",
    "# dataset = load_dataset(\"emotion\", \"default\", split = 'train')\n",
    "# full_df = pd.DataFrame(dataset, columns = ['text', 'label'])\n",
    "# full_df = full_df[0:10000]\n",
    "full_df = pd.read_csv('transcript_may_collated_encoded.csv')\n",
    "full_df = full_df.drop(columns='Unnamed: 0')\n",
    "full_df.rename(columns={'accepted_flg':'label', 'encrypted_collated_transcription':'text'}, inplace=True)\n",
    "full_df = full_df.dropna()\n",
    "full_df['label'] = full_df['label'].astype(str)\n",
    "full_df = full_df[0:10000]\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d4d145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 266230 entries, 0 to 266496\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   ID                266230 non-null  object\n",
      " 1   sales_offer_date  266230 non-null  object\n",
      " 2   label             266230 non-null  object\n",
      " 3   text              266230 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0efd5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'text'\n",
    "label_col = 'label'\n",
    "checkpoint = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint, is_split_into_words = True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92f43e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf3797ed1b445ddb0ca2ab4dee1d223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0ef21dac9a445facbcaf2676e6b370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alldata_ds = Dataset.from_pandas(full_df)\n",
    "alldata_ds = alldata_ds.class_encode_column(label_col)\n",
    "data_ds = alldata_ds.train_test_split(test_size=0.4, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66aba508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d273f7128031431bb5b241d3dae118c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b461d8dc4854487e92193f5290dd1f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define tokenizing function\n",
    "def tokenize_inputs(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, is_split_into_words = True)\n",
    "    return tokenizer(text[text_col], truncation=True)\n",
    "    \n",
    "# do the tokenizing using map function\n",
    "tokenized_ds = data_ds.map(tokenize_inputs, batched=True,\n",
    "                           remove_columns = list(set(full_df.columns.to_list()).difference(set([text_col, label_col]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df1a8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = data_ds['train'].features[label_col].num_classes\n",
    "id2label = {ind:label for ind, label in enumerate(data_ds['train'].features[label_col].names)}\n",
    "label2id = {label:ind for ind, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8dbea5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"False\",\n",
      "    \"1\": \"True\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"False\": 0,\n",
      "    \"True\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
    "                                                           num_labels = no_classes,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "627f42f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_arg = TrainingArguments(\"test-trainer\",\n",
    "                                 logging_strategy='epoch',\n",
    "                                 evaluation_strategy = 'epoch',\n",
    "                                 save_strategy = 'epoch', \n",
    "                                 load_best_model_at_end = True,\n",
    "                                 metric_for_best_model='fscore',\n",
    "                                 greater_is_better=True,\n",
    "                                 report_to = 'all',\n",
    "                                 per_device_train_batch_size = 16,\n",
    "                                 per_device_eval_batch_size = 16, \n",
    "                                 num_train_epochs = 3,\n",
    "                                 seed = 42\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f97d5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    #get predictions by using index of max logit\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    #calculate classification report\n",
    "    perfs = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    perf_dict = dict(zip(['precision', 'recall', 'fscore'], perfs[:3]))\n",
    "    \n",
    "    #return dictionary\n",
    "    return perf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "044db2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model,\n",
    "                  args=training_arg,\n",
    "                  data_collator = data_collator,\n",
    "                  tokenizer=tokenizer,\n",
    "                  train_dataset = tokenized_ds['train'],\n",
    "                  eval_dataset = tokenized_ds['test'],\n",
    "                  compute_metrics = compute_metrics\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7dd2e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 6000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.245592</td>\n",
       "      <td>0.466625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.466625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.466625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to test-trainer/checkpoint-47\n",
      "Configuration saved in test-trainer/checkpoint-47/config.json\n",
      "Model weights saved in test-trainer/checkpoint-47/pytorch_model.bin\n",
      "tokenizer config file saved in test-trainer/checkpoint-47/tokenizer_config.json\n",
      "Special tokens file saved in test-trainer/checkpoint-47/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to test-trainer/checkpoint-94\n",
      "Configuration saved in test-trainer/checkpoint-94/config.json\n",
      "Model weights saved in test-trainer/checkpoint-94/pytorch_model.bin\n",
      "tokenizer config file saved in test-trainer/checkpoint-94/tokenizer_config.json\n",
      "Special tokens file saved in test-trainer/checkpoint-94/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to test-trainer/checkpoint-141\n",
      "Configuration saved in test-trainer/checkpoint-141/config.json\n",
      "Model weights saved in test-trainer/checkpoint-141/pytorch_model.bin\n",
      "tokenizer config file saved in test-trainer/checkpoint-141/tokenizer_config.json\n",
      "Special tokens file saved in test-trainer/checkpoint-141/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-trainer/checkpoint-47 (score: 0.48273632484158796).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=141, training_loss=0.24879091682163537, metrics={'train_runtime': 87.1411, 'train_samples_per_second': 206.562, 'train_steps_per_second': 1.618, 'total_flos': 4735998996480000.0, 'train_loss': 0.24879091682163537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8cde989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24559175968170166, 'eval_precision': 0.466625, 'eval_recall': 0.5, 'eval_fscore': 0.48273632484158796, 'eval_runtime': 6.1037, 'eval_samples_per_second': 655.339, 'eval_steps_per_second': 5.243, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "eval_ds = trainer.evaluate(tokenized_ds['test'])\n",
    "print(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68488b03",
   "metadata": {},
   "source": [
    "## Using Specified Pipeline without Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957280fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"emotion\", \"default\", split = 'validation')\n",
    "# full_df = pd.DataFrame(dataset, columns = ['text', 'label'])\n",
    "# full_df = full_df[0:100]\n",
    "# full_df.loc[full_df['label'] == 0, 'label_str'] = 'sadness'\n",
    "# full_df.loc[full_df['label'] == 1, 'label_str'] = 'joy'\n",
    "# full_df.loc[full_df['label'] == 2, 'label_str'] = 'love'\n",
    "# full_df.loc[full_df['label'] == 3, 'label_str'] = 'anger'\n",
    "# full_df.loc[full_df['label'] == 4, 'label_str'] = 'fear'\n",
    "# full_df.loc[full_df['label'] == 5, 'label_str'] = 'surprise'\n",
    "# full_df.info()\n",
    "# full_df = pd.read_csv('sample.csv')\n",
    "full_df = pd.read_csv('transcript_may_encoded_100.csv', index_col='Unnamed: 0')\n",
    "full_df.rename(columns={'accepted_flg':'label', 'encrypted_collated_transcription':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7d1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[['label', 'text']]\n",
    "full_df.loc[full_df['label'] == False, 'label_str'] = 'Negative'\n",
    "full_df.loc[full_df['label'] == True, 'label_str'] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47e8dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech for speaki...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[CLIENT] tech My name is [NAME]. May I have yo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for call. tech you're speaking w...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Barcode Coa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text label_str\n",
       "0  False  Thank you for calling [CLIENT] Tech for speaki...  Negative\n",
       "1  False  [CLIENT] tech My name is [NAME]. May I have yo...  Negative\n",
       "4  False  Hi. Thank you for call. tech you're speaking w...  Negative\n",
       "5  False  Thank you for calling [CLIENT] Tech Coach. My ...  Negative\n",
       "6  False  Hi. Thank you for calling [CLIENT] Barcode Coa...  Negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446ee552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    0.913043\n",
       "Positive    0.086957\n",
       "Name: label_str, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['label_str'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3080941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sentiment_analysis(df, mypipeline:str, mylabels:list, text_col:str):\n",
    "    \"\"\"\n",
    "    run sentiment analysis on text using specified pipeline\n",
    "    \n",
    "    Args:\n",
    "        df: data frame\n",
    "        mypipeline (str): specified pipeline \n",
    "        mylabes (list): list of specified labels\n",
    "        text_col (str): name of text column\n",
    "        \n",
    "    Returns:\n",
    "        predictions (list): predicted labels with the highest scores\n",
    "        scores (list): sentiment analysis scores for the predictions\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    classifier = pipeline(mypipeline, device = 0)\n",
    "    candidate_labels = mylabels\n",
    "    preds = [classifier(sequence, candidate_labels) for sequence in df[text_col].tolist()]\n",
    "    predictions = [pred['labels'][0] for pred in preds]\n",
    "    scores = [pred['scores'][0] for pred in preds]\n",
    "    print(time.time() - start_time, 'seconds')\n",
    "    return predictions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e606160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.83779811859131 seconds\n"
     ]
    }
   ],
   "source": [
    "predictions, scores = run_sentiment_analysis(df = full_df, \n",
    "                                             mypipeline = \"zero-shot-classification\",\n",
    "                                             mylabels = ['Positive', 'Negative'],\n",
    "#                                              mylabels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"], \n",
    "                                             text_col = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff12b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.02      0.05        42\n",
      "    Positive       0.09      1.00      0.16         4\n",
      "\n",
      "    accuracy                           0.11        46\n",
      "   macro avg       0.54      0.51      0.10        46\n",
      "weighted avg       0.92      0.11      0.06        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(full_df['label_str'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cfb884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_str</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech for speaki...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.746940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[CLIENT] tech My name is [NAME]. May I have yo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.582443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for call. tech you're speaking w...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.573833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. My ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.757156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for calling [CLIENT] Barcode Coa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.703341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>Thank you for calling Coach. This is Sean spea...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.584938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>Thank you for calling [CLIENT] Tech Coach. Ben...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.582232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>Morning. Thanks for [CLIENT] Tech Coach. My na...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.776038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>thank Hello? Hi. Thank you for calling [CLIENT...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.552441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>Hi. Thank you for [CLIENT] Tech Coach. My name...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.590711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text label_str  \\\n",
       "0   False  Thank you for calling [CLIENT] Tech for speaki...  Negative   \n",
       "1   False  [CLIENT] tech My name is [NAME]. May I have yo...  Negative   \n",
       "4   False  Hi. Thank you for call. tech you're speaking w...  Negative   \n",
       "5   False  Thank you for calling [CLIENT] Tech Coach. My ...  Negative   \n",
       "6   False  Hi. Thank you for calling [CLIENT] Barcode Coa...  Negative   \n",
       "7   False  Thank you for calling Coach. This is Sean spea...  Negative   \n",
       "9    True  Thank you for calling [CLIENT] Tech Coach. Ben...  Positive   \n",
       "10  False  Morning. Thanks for [CLIENT] Tech Coach. My na...  Negative   \n",
       "11  False  thank Hello? Hi. Thank you for calling [CLIENT...  Negative   \n",
       "12  False  Hi. Thank you for [CLIENT] Tech Coach. My name...  Negative   \n",
       "\n",
       "   sentiment     score  \n",
       "0   Positive  0.746940  \n",
       "1   Positive  0.582443  \n",
       "4   Positive  0.573833  \n",
       "5   Positive  0.757156  \n",
       "6   Positive  0.703341  \n",
       "7   Positive  0.584938  \n",
       "9   Positive  0.582232  \n",
       "10  Positive  0.776038  \n",
       "11  Positive  0.552441  \n",
       "12  Positive  0.590711  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full_df.copy()\n",
    "df['sentiment'] = predictions\n",
    "df['score'] = scores\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2898888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sentiment_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a2069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
